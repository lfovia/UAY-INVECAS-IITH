{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"radar128x64_pix2pix.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"forty-officer","executionInfo":{"status":"ok","timestamp":1615808668958,"user_tz":-330,"elapsed":4603,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["import tensorflow as tf\n","sess = tf.compat.v1.Session()\n","\n","tf.compat.v1.keras.backend.set_session(sess)"],"id":"forty-officer","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrong-newton","executionInfo":{"status":"ok","timestamp":1615808668960,"user_tz":-330,"elapsed":4593,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["import numpy as np\n","from numpy import mean\n","from numpy import std\n","from numpy import dstack\n","from numpy import zeros\n","from numpy import ones\n","from numpy.random import randint\n","\n","import re\n","\n","import json\n","\n","import pandas as pd\n","from pandas import json_normalize\n","\n","from keras.optimizers import Adam\n","from keras.initializers import RandomNormal\n","from keras.models import Model\n","from keras.models import Input\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","from keras.layers import LeakyReLU\n","\n","from matplotlib import pyplot\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import confusion_matrix"],"id":"wrong-newton","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"destroyed-tablet","executionInfo":{"status":"ok","timestamp":1615808669364,"user_tz":-330,"elapsed":4993,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["def loadData(path):\n","    with open(path,'r') as handle:\n","        text_data = handle.read()\n","        json_data = json.loads(text_data)\n","        df = pd.DataFrame(json_data)\n","    return df\n","\n","\n","#Adding frame numbers for time series plots\n","def LabelFrame(data):   \n","    df = pd.DataFrame(data)\n","    for i in range(len(df.ObjectList.index)):\n","        for j in df['ObjectList'][i]:\n","            j['Frame'] = i\n","            \n","    df.to_json('temp.json',orient = 'records')\n","    with open('temp.json') as file:\n","        data2 = file.read()\n","        jasondata = json.loads(data2)\n","    return jasondata\n","\n","\n","def openfile(path):\n","    with open(path, 'r') as handle:\n","        text_data = handle.read()\n","        text_data = '[' + re.sub(r'\\}\\s\\{','},{', text_data) + ']'\n","        json_data = json.loads(text_data)\n","        json_data = LabelFrame(json_data)\n","    return json_data\n","\n","\n","#Seperating pk array values into columns\n","def mergedframe1(df_1):\n","        frames = [df_1]\n","        df_merged = pd.concat(frames,ignore_index = True)\n","        df_classify = pd.DataFrame()\n","        df_classify[['ObjType','pkArray','dpplIdx']] = df_merged[['ObjType','pkArray','dpplIdx']]\n","        \n","        df_classify['pkArray'] = df_classify['pkArray'].apply(lambda pkarray:np.ravel(np.transpose(pkarray)))\n","        \n","        all_list = []\n","\n","        for i in range(35):\n","            for j in range(len(df_classify.index)):\n","                all_list.append(df_classify.pkArray[j][i])\n","        chunk = [all_list[i:i+len(df_classify.index)] for i in range(0, len(all_list), len(df_classify.index))]\n","        df_classify1 = pd.DataFrame(chunk)\n","        dfclassify=df_classify1.transpose()\n","        dfclassify['ObjType'] = df_classify['ObjType']\n","        dfclassify['rangeIdx'] = df_merged['rangeIdx']\n","        dfclassify['dpplIdx'] = df_merged['dpplIdx']\n","        dfclassify['pkArray'] = df_merged['pkArray']\n","        dfclassify['Range'] = df_merged['Range']\n","        dfclassify['Coordinates.X'] = df_merged['Coordinates.X']\n","        dfclassify['Coordinates.Y'] = df_merged['Coordinates.Y']\n","        dfclassify[\"pkValue1.Real\"] = df_merged[\"pkValue1.Real\"]\n","        dfclassify[\"pkValue1.Imaginary\"] = df_merged['pkValue1.Imaginary']\n","        dfclassify[\"pkValue2.Real\"] = df_merged[\"pkValue2.Real\"]\n","        dfclassify[\"pkValue2.Imaginary\"] = df_merged['pkValue2.Imaginary']\n","        dfclassify[\"pkValue3.Real\"] = df_merged[\"pkValue3.Real\"]\n","        dfclassify[\"pkValue3.Imaginary\"] = df_merged['pkValue3.Imaginary']\n","        dfclassify[\"pkValue4.Real\"] = df_merged[\"pkValue4.Real\"]\n","        dfclassify[\"pkValue4.Imaginary\"] = df_merged['pkValue4.Imaginary']\n","        \n","        dfclassify['Frame'] = df_merged['Frame']\n","        dfclassify['Range'] = df_merged['Range']\n","        return dfclassify\n","\n","\n","# Load all files from json to a dataframe after \n","def startdf(json_data,Label):\n","    df_1= pd.DataFrame()\n","    df1 = pd.DataFrame((json_data))\n","    for j in range(len(df1.index)):\n","        df2 = json_normalize(df1['ObjectList'][j])\n","        df2['ObjType'] = df2['ObjType'].map(lambda ObjType: Label)        \n","        #df2 = df2[df2.Range <= UIdx]\n","        #df2 = df2[df2.Range >= LIdx]\n","        #df2 = df2[df2.dpplIdx == 1]   \n","        df_1 = pd.concat([df2,df_1],ignore_index =True)\n","    df_1 = df_1.sort_values(by=['Frame'],ascending = True)\n","    df_1 = df_1.reset_index(drop=True)\n","    df_1['pkArray'] = df_1['pkArray'].map(lambda x:np.transpose(x))\n","    df_final = mergedframe1(df_1)\n","    return df_final\n","\n","\n","def labelData(df, x1, x2, y1, y2, label):\n","    df['ObjType'] = df['ObjType'].map(lambda x : 0)\n","\n","    for index, row in df.iterrows():\n","        if ((row['Coordinates.X'] > x1) & (row['Coordinates.X'] < x2) \n","        & (row['Coordinates.Y'] > y1) & (row['Coordinates.Y'] < y2)):\n","            df.at[index, 'ObjType'] = label\n","        else:\n","            df.at[index, 'ObjType'] = 0\n","    return df\n","\n","\n","# Shuffle two arrays in unison\n","def unison_shuffled_copies(array1, array2):\n","    assert len(array1) == len(array2)\n","    p = np.random.permutation(len(array1))\n","    return array1[p], array2[p]\n","\n","\n","def padHumanRows(df):\n","  for ind, row in df.iterrows():\n","    if ((ind % 10) == 0):\n","      count = 0\n","      while ((count < 10) and (df.iloc[ind + count]['Frame'] == int(ind/10))):\n","        count = count + 1\n","        if ((ind + count) == len(df.index)):\n","          break\n","      while (count < 10):\n","        row = pd.DataFrame({\"0\": 0, \"1\": 0, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0, \"10\": 0, \"11\": 0, \"12\": 0, \"13\": 0, \"14\": 0, \"15\": 0, \"16\": 0, \"17\": 0, \"18\": 0, \"19\": 0, \"20\": 0, \"21\": 0, \"22\": 0, \"23\": 0, \"24\": 0, \"25\": 0, \"26\": 0, \"27\": 0, \"28\": 0, \"29\": 0, \"30\": 0, \"31\": 0, \"32\": 0, \"33\": 0, \"34\": 0, \"rangeIdx\":0, \"dpplIdx\":0, \"Frame\": ind/10, \"ObjType\":0}, index=[ind+count-1+0.5])\n","        df = df.append(row, ignore_index=False)\n","        df = df.sort_index().reset_index(drop=True)\n","        df = df.reindex([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"rangeIdx\", \"dpplIdx\", \"Frame\", \"ObjType\"], axis=1)\n","        count = count + 1\n","  return df\n","\n","def padCarRows(df):\n","  for ind, row in df.iterrows():\n","    if ((ind % 10) == 0):\n","      count = 0\n","      while ((count < 10) and (df.iloc[ind + count]['Frame'] == int(ind/10))):\n","        count = count + 1\n","        if ((ind + count) == len(df.index)):\n","          break\n","      while (count < 10):\n","        row = pd.DataFrame({0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, \"rangeIdx\":0, \"dpplIdx\":0, \"Frame\": ind/10, \"ObjType\":0}, index=[ind+count-1+0.5])\n","        df = df.append(row, ignore_index=False)\n","        df = df.sort_index().reset_index(drop=True)\n","        df = df.reindex([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, \"rangeIdx\", \"dpplIdx\", \"Frame\", \"ObjType\"], axis=1)\n","        count = count + 1\n","  return df\n","\n","\n","def padRows(df, obj):\n","  if (obj == \"car\"):\n","    while (df.shape[0] != ((df['Frame'].max() + 1)*10)):\n","      df = padCarRows(df)\n","  else:\n","    while (df.shape[0] != ((df['Frame'].max() + 1)*10)):\n","      df = padHumanRows(df)  \n","  return df\n","\n","\n","def truncateColumns(df):\n","  df = df.drop(['Range', 'pkArray', 'Coordinates.X', 'Coordinates.Y', 'pkValue1.Real', \n","           'pkValue1.Imaginary', 'pkValue2.Real', 'pkValue2.Imaginary', \n","           'pkValue3.Real', 'pkValue3.Imaginary', 'pkValue4.Real', \n","           'pkValue4.Imaginary', 'ObjType'], axis=1)\n","  return df\n","\n","\n","def dfTo2DArray(df):\n","  df = df[df.columns[0:38]].values\n","  return df\n","\n","#to correct the dppl idx\n","def correctDpplIdx(x):\n","    if x <=31:\n","        return x\n","    if x>31:\n","        return x-64\n","\n","\n","# frameTo128x64() function converts a 2D input array\n","# where rows == objects in json file and cols == 0,1,..34 peak array elements, rangeIdx, dopplIdx, Frame.\n","# The 2D array is converted to 3D array of size no. of frames * 128 * 64\n","\n","def frameTo128x64(arr):\n","    count = 0\n","    new3DArray = np.empty((1, 128, 64))\n","    newLabelArr = np.empty((1, 128, 64))\n","    arr128x64 = np.zeros((128, 64))\n","    labelArr = np.zeros((128, 64))\n","    for row in range(0, np.shape(arr)[0], 1):\n","        if count<=10:\n","            rangeIndex = int(arr[row][35])\n","            dopplerIndex = int(correctDpplIdx(arr[row][36]))\n","            label = arr[row][37]\n","            r = 0\n","            \n","            for rangeID in range(rangeIndex-3, rangeIndex+4, 1):\n","                d = 0\n","                for dopplID in range(dopplerIndex-2, dopplerIndex+3, 1):\n","                    if ((0 <= rangeID <= 127) and (-32 <= dopplID <= 31)):\n","                        if(arr128x64[rangeID][dopplID+32] < arr[row][(d * 7) + r]):\n","                            arr128x64[rangeID][dopplID+32] = arr[row][(d * 7) + r]\n","                        if(labelArr[rangeID][dopplID+32] == 0):\n","                            labelArr[rangeID][dopplID+32] = label\n","                    d = d + 1\n","                r = r + 1\n","        count= count + 1\n","        if count == 10:\n","            count = 0\n","            arr128x64 = np.reshape(arr128x64, (1, 128, 64))\n","            labelArr = np.reshape(labelArr, (1, 128, 64))\n","            new3DArray = np.append(new3DArray, arr128x64, axis=0)\n","            newLabelArr = np.append(newLabelArr, labelArr, axis=0)\n","            arr128x64 = np.zeros((128, 64))\n","            labelArr = np.zeros((128, 64))\n","    return new3DArray[1:, :, :], newLabelArr[1:, :, :]"],"id":"destroyed-tablet","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"atmospheric-species","executionInfo":{"status":"ok","timestamp":1615813695252,"user_tz":-330,"elapsed":4348,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["humanDay1_2pm = loadData(\"/content/RadarDataset/human/human_2pm.json\")\n","humanDay1_5pm = loadData(\"/content/RadarDataset/human/human_5pm.json\")\n","#/content/RadarDataset/human/human_2pm.json\n","humanDay1_9pm = loadData(\"/content/RadarDataset/human/human_9pm.json\")\n","humanDay1_3pm = loadData(\"/content/RadarDataset/human/human_3pm.json\")\n","humanDay1_6pm = loadData(\"/content/RadarDataset/human/human_6pm.json\")"],"id":"atmospheric-species","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"headed-theorem","executionInfo":{"status":"ok","timestamp":1615813785792,"user_tz":-330,"elapsed":54949,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["carVday2_5 = startdf(openfile(\"/content/RadarDataset/carV/Car Vertical_5_28_02_2020 12_38_17.json\"), 2)\n","carVday1_6 = startdf(openfile(\"/content/RadarDataset/carV/Car Vertical_6_27_01_2020 12_42_51.json\"), 2)\n","carVday1_10 = startdf(openfile(\"/content/RadarDataset/carV/Car Vertical_10_27_01_2020 12_46_59.json\"), 2)\n","carVday2_11 = startdf(openfile(\"/content/RadarDataset/carV/Car Vertical_11_28_02_2020 13_00_06.json\"), 2)\n","carVday2_15 = startdf(openfile(\"/content/RadarDataset/carV/Car Vertical_15_28_02_2020 13_23_56.json\"), 2)\n","carVday1_16 = startdf(openfile(\"/content/RadarDataset/carV/Car Vertical_16_27_01_2020 12_53_52.json\"), 2)\n","carVday2_20 = startdf(openfile(\"/content/RadarDataset/carV/Car Vertical_20_28_02_2020 15_38_52.json\"), 2)\n","carVday1_19 = startdf(openfile(\"/content/RadarDataset/carV/Car Vertical_19_27_01_2020 12_57_35.json\"), 2)"],"id":"headed-theorem","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"wired-biodiversity","executionInfo":{"status":"ok","timestamp":1615813830423,"user_tz":-330,"elapsed":43351,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["carHday1_5 = startdf(openfile(\"/content/RadarDataset/carH/Car Horizontal_5_27_01_2020 13_05_27.json\"), 3)\n","carHday1_7 = startdf(openfile(\"/content/RadarDataset/carH/Car Horizontal_7_27_01_2020 13_07_36.json\"), 3)\n","carHday1_11 = startdf(openfile(\"/content/RadarDataset/carH/Car Horizontal_11_27_01_2020 13_40_38.json\"), 3)\n","carHday1_17 = startdf(openfile(\"/content/RadarDataset/carH/Car Horizontal_17_27_01_2020 13_17_50.json\"), 3)\n","carHday1_20 = startdf(openfile(\"/content/RadarDataset/carH/Car Horizontal_20_27_01_2020 13_21_11.json\"), 3)\n","carHday2_2 = startdf(openfile(\"/content/RadarDataset/carH/Car Horizontal_2_12_03_2020 14_50_24.json\"), 3)\n","carHday2_4 = startdf(openfile(\"/content/RadarDataset/carH/Car Horizontal_4_12_03_2020 14_53_38.json\"), 3)\n","carHday2_6 = startdf(openfile(\"/content/RadarDataset/carH/Car Horizontal_6_12_03_2020 15_00_25.json\"), 3)"],"id":"wired-biodiversity","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"unable-receiver","executionInfo":{"status":"ok","timestamp":1615814008154,"user_tz":-330,"elapsed":158173,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["arrHumanDay1_2pm, labelHumanDay1_2pm = frameTo128x64(dfTo2DArray(padRows(labelData(humanDay1_2pm, -0.5, 0.5, 0.1, 7.9, 1), \"human\")))\n","arrHumanDay1_5pm, labelHumanDay1_5pm = frameTo128x64(dfTo2DArray(padRows(labelData(humanDay1_5pm, -0.5, 0.5, 0.1, 7.9, 1), \"human\")))\n","arrHumanDay1_9pm, labelHumanDay1_9pm = frameTo128x64(dfTo2DArray(padRows(labelData(humanDay1_9pm, -0.5, 0.5, 0.1, 7.9, 1), \"human\")))\n","arrHumanDay1_3pm, labelHumanDay1_3pm = frameTo128x64(dfTo2DArray(padRows(labelData(humanDay1_3pm, -0.5, 0.5, 0.1, 7.9, 1), \"human\")))\n","arrHumanDay1_6pm, labelHumanDay1_6pm = frameTo128x64(dfTo2DArray(padRows(labelData(humanDay1_6pm, -0.5, 0.5, 0.1, 7.9, 1), \"human\")))"],"id":"unable-receiver","execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"relative-excess","executionInfo":{"status":"ok","timestamp":1615814172488,"user_tz":-330,"elapsed":321259,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["arrCarVday1_6, labelCarVday1_6 = frameTo128x64(dfTo2DArray(padRows(labelData(carVday1_6, -1.5, 1.5, 5.5, 7.5, 2), \"car\")))\n","arrCarVday1_10, labelCarVday1_10 = frameTo128x64(dfTo2DArray(padRows(labelData(carVday1_10, -1.5, 1.5, 9.5, 11.5, 2), \"car\")))\n","arrCarVday1_16, labelCarVday1_16 = frameTo128x64(dfTo2DArray(padRows(labelData(carVday1_16, -1.5, 1.5, 15.5, 17.5, 2), \"car\")))\n","arrCarVday1_19, labelCarVday1_19 = frameTo128x64(dfTo2DArray(padRows(labelData(carVday1_19, -1.5, 1.5, 18.5, 20.5, 2), \"car\")))\n","arrCarVday2_5, labelCarVday2_5 = frameTo128x64(dfTo2DArray(padRows(labelData(carVday2_5, -1.5, 1.5, 4.5, 6.5, 2), \"car\")))\n","arrCarVday2_15, labelCarVday2_15 = frameTo128x64(dfTo2DArray(padRows(labelData(carVday2_15, -1.5, 1.5, 14.5, 16.5, 2), \"car\")))\n","arrCarVday2_11, labelCarVday2_11 = frameTo128x64(dfTo2DArray(padRows(labelData(carVday2_11, -1.5, 1.5, 10.5, 12.5, 2), \"car\")))\n","arrCarVday2_20, labelCarVday2_20 = frameTo128x64(dfTo2DArray(padRows(labelData(carVday2_20, -1.5, 1.5, 19.5, 21.5, 2), \"car\")))"],"id":"relative-excess","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"august-religious","executionInfo":{"status":"ok","timestamp":1615814343115,"user_tz":-330,"elapsed":490319,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["arrCarHday1_5, labelCarHday1_5 = frameTo128x64(dfTo2DArray(padRows(labelData(carHday1_5, -3, 3, 4.5, 7, 3), \"car\")))\n","arrCarHday1_7, labelCarHday1_7 = frameTo128x64(dfTo2DArray(padRows(labelData(carHday1_7, -3, 3, 6.5, 9, 3), \"car\")))\n","arrCarHday1_11, labelCarHday1_11 = frameTo128x64(dfTo2DArray(padRows(labelData(carHday1_11, -3, 3, 10.5, 13, 3), \"car\")))\n","arrCarHday1_17, labelCarHday1_17 = frameTo128x64(dfTo2DArray(padRows(labelData(carHday1_17, -3, 3, 16.5, 19, 3), \"car\")))\n","arrCarHday1_20, labelCarHday1_20 = frameTo128x64(dfTo2DArray(padRows(labelData(carHday1_20, -3, 3, 19.5, 22, 3), \"car\")))\n","arrCarHday2_2, labelCarHday2_2 = frameTo128x64(dfTo2DArray(padRows(labelData(carHday2_2, -3, 3, 1.5, 4, 3), \"car\")))\n","arrCarHday2_4, labelCarHday2_4 = frameTo128x64(dfTo2DArray(padRows(labelData(carHday2_4, -3, 3, 3.5, 6, 3), \"car\")))\n","arrCarHday2_6, labelCarHday2_6 = frameTo128x64(dfTo2DArray(padRows(labelData(carHday2_6, -3, 3, 5.5, 8, 3), \"car\")))"],"id":"august-religious","execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"declared-property","executionInfo":{"status":"ok","timestamp":1615814343153,"user_tz":-330,"elapsed":486223,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}},"outputId":"1fa698b8-aaff-4425-b6ac-d4f38f8b9ff8"},"source":["print(\"Human Data:\\narrHumanDay1_2pm:\", arrHumanDay1_2pm.shape, \"  labelHumanDay1_2pm:\", labelHumanDay1_2pm.shape, \n","      \"\\narrHumanDay1_5pm:\", arrHumanDay1_5pm.shape, \"  labelHumanDay1_5pm:\", labelHumanDay1_5pm.shape, \"\\narrHumanDay1_9pm:\", \n","      arrHumanDay1_9pm.shape, \"  labelHumanDay1_9pm:\", labelHumanDay1_9pm.shape, \"\\narrHumanDay1_3pm:\", arrHumanDay1_3pm.shape,\n","      \"  labelHumanDay1_3pm:\", labelHumanDay1_3pm.shape, \"\\narrHumanDay1_6pm:\", arrHumanDay1_6pm.shape, \"  labelHumanDay1_6pm:\", labelHumanDay1_6pm.shape)\n","\n","print(\"\\ncarV Data:\\narrCarVday1_6:\", arrCarVday1_6.shape, \"  labelCarVday1_6:\", labelCarVday1_6.shape,\n","      \"\\narrCarVday1_10:\", arrCarVday1_10.shape, \"  labelCarVday1_10:\", labelCarVday1_10.shape, \"\\narrCarVday1_16:\", \n","      arrCarVday1_16.shape, \"  labelCarVday1_16:\", labelCarVday1_16.shape, \"\\narrCarVday1_19:\", arrCarVday1_19.shape, \n","      \"  labelCarVday1_19:\", labelCarVday1_19.shape, \"\\narrCarVday2_5:\", arrCarVday2_5.shape, \"  labelCarVday2_5:\", labelCarVday2_5.shape, \"\\narrCarVday2_15:\", \n","      arrCarVday2_15.shape, \"  labelCarVday2_15:\", labelCarVday2_15.shape, \"\\narrCarVday2_11:\", arrCarVday2_11.shape, \n","      \"  labelCarVday2_11:\", labelCarVday2_11.shape, \"\\narrCarVday2_20:\", arrCarVday2_20.shape, \"  labelCarVday2_20:\", labelCarVday2_20.shape)\n","\n","print(\"\\ncarH Data:\\narrCarHday1_5:\", arrCarHday1_5.shape, \"  labelCarHday1_5:\", labelCarHday1_5.shape, \"\\narrCarHday1_7:\", \n","      arrCarHday1_7.shape, \"  labelCarHday1_7:\", labelCarHday1_7.shape, \"\\narrCarHday1_11:\", arrCarHday1_11.shape, \n","      \"  labelCarHday1_11:\", labelCarHday1_11.shape, \"\\narrCarHday1_17:\", arrCarHday1_17.shape, \"  labelCarHday1_17:\", labelCarHday1_17.shape, \"\\narrCarHday1_20:\", \n","      arrCarHday1_20.shape, \"  labelCarHday1_20:\", labelCarHday1_20.shape, \"\\narrCarHday2_2:\", arrCarHday2_2.shape, \n","      \"  labelCarHday2_2:\", labelCarHday2_2.shape, \"\\narrCarHday2_6:\", arrCarHday2_6.shape, \"  labelCarHday2_6:\", labelCarHday2_6.shape, \"\\narrCarHday2_4:\", \n","      arrCarHday2_4.shape, \"  labelCarHday2_4:\", labelCarHday2_4.shape)"],"id":"declared-property","execution_count":23,"outputs":[{"output_type":"stream","text":["Human Data:\n","arrHumanDay1_2pm: (894, 128, 64)   labelHumanDay1_2pm: (894, 128, 64) \n","arrHumanDay1_5pm: (998, 128, 64)   labelHumanDay1_5pm: (998, 128, 64) \n","arrHumanDay1_9pm: (998, 128, 64)   labelHumanDay1_9pm: (998, 128, 64) \n","arrHumanDay1_3pm: (997, 128, 64)   labelHumanDay1_3pm: (997, 128, 64) \n","arrHumanDay1_6pm: (997, 128, 64)   labelHumanDay1_6pm: (997, 128, 64)\n","\n","carV Data:\n","arrCarVday1_6: (345, 128, 64)   labelCarVday1_6: (345, 128, 64) \n","arrCarVday1_10: (334, 128, 64)   labelCarVday1_10: (334, 128, 64) \n","arrCarVday1_16: (383, 128, 64)   labelCarVday1_16: (383, 128, 64) \n","arrCarVday1_19: (331, 128, 64)   labelCarVday1_19: (331, 128, 64) \n","arrCarVday2_5: (998, 128, 64)   labelCarVday2_5: (998, 128, 64) \n","arrCarVday2_15: (1001, 128, 64)   labelCarVday2_15: (1001, 128, 64) \n","arrCarVday2_11: (994, 128, 64)   labelCarVday2_11: (994, 128, 64) \n","arrCarVday2_20: (1000, 128, 64)   labelCarVday2_20: (1000, 128, 64)\n","\n","carH Data:\n","arrCarHday1_5: (366, 128, 64)   labelCarHday1_5: (366, 128, 64) \n","arrCarHday1_7: (325, 128, 64)   labelCarHday1_7: (325, 128, 64) \n","arrCarHday1_11: (362, 128, 64)   labelCarHday1_11: (362, 128, 64) \n","arrCarHday1_17: (312, 128, 64)   labelCarHday1_17: (312, 128, 64) \n","arrCarHday1_20: (323, 128, 64)   labelCarHday1_20: (323, 128, 64) \n","arrCarHday2_2: (897, 128, 64)   labelCarHday2_2: (897, 128, 64) \n","arrCarHday2_6: (1000, 128, 64)   labelCarHday2_6: (1000, 128, 64) \n","arrCarHday2_4: (1000, 128, 64)   labelCarHday2_4: (1000, 128, 64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"legislative-algeria","executionInfo":{"status":"ok","timestamp":1615814364808,"user_tz":-330,"elapsed":3768,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["inputArrays = np.concatenate((arrHumanDay1_2pm, arrCarVday1_6, arrCarHday1_5, arrCarVday1_10, arrCarHday1_7, \n","                             arrHumanDay1_5pm, arrCarVday1_16, arrCarHday1_11, arrCarVday1_19, arrCarHday1_20, \n","                             arrHumanDay1_9pm, arrCarVday2_5, arrCarHday1_17, arrCarVday2_15, arrCarHday2_2, \n","                             arrHumanDay1_3pm, arrCarVday2_11, arrCarHday2_6, arrHumanDay1_6pm, arrCarVday2_20, \n","                             arrCarHday2_4), axis=0)\n","\n","targetArrays = np.concatenate((labelHumanDay1_2pm, labelCarVday1_6, labelCarHday1_5, labelCarVday1_10, labelCarHday1_7, \n","                             labelHumanDay1_5pm, labelCarVday1_16, labelCarHday1_11, labelCarVday1_19, labelCarHday1_20, \n","                             labelHumanDay1_9pm, labelCarVday2_5, labelCarHday1_17, labelCarVday2_15, labelCarHday2_2, \n","                             labelHumanDay1_3pm, labelCarVday2_11, labelCarHday2_6, labelHumanDay1_6pm, labelCarVday2_20, \n","                             labelCarHday2_4), axis=0)\n","\n","inputArrays = np.reshape(inputArrays, (inputArrays.shape[0], 128, 64, 1))\n","targetArrays = np.reshape(targetArrays, (targetArrays.shape[0], 128, 64, 1))\n","\n","inputArrays, targetArrays = shuffle(inputArrays, targetArrays, random_state=0)"],"id":"legislative-algeria","execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"latin-advocacy","executionInfo":{"status":"ok","timestamp":1615814364820,"user_tz":-330,"elapsed":2635,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["# define the discriminator model\n","\n","def define_discriminator(image_shape):\n","    # weight initialization\n","    init = RandomNormal(stddev=0.02)\n","    # source image input\n","    in_src_image = Input(shape=image_shape)\n","    # target image input\n","    in_target_image = Input(shape=image_shape)\n","    # concatenate images channel-wise\n","    merged = Concatenate()([in_src_image, in_target_image])\n","    # C64\n","    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    # C128\n","    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","    d = BatchNormalization()(d)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    # C256\n","    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","    d = BatchNormalization()(d)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    # C512\n","    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","    d = BatchNormalization()(d)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    # second last output layer\n","    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n","    d = BatchNormalization()(d)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    # patch output\n","    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n","    patch_out = Activation('sigmoid')(d)\n","    # define model\n","    model = Model([in_src_image, in_target_image], patch_out)\n","    # compile model\n","    opt = Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n","    return model"],"id":"latin-advocacy","execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"similar-rolling","executionInfo":{"status":"ok","timestamp":1615814371519,"user_tz":-330,"elapsed":2068,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["# define an encoder block\n","def define_encoder_block(layer_in, n_filters, batchnorm=True):\n","    # weight initialization\n","    init = RandomNormal(stddev=0.02)\n","    # add downsampling layer\n","    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n","    # conditionally add batch normalization\n","    if batchnorm:\n","        g = BatchNormalization()(g, training=True)\n","    # leaky relu activation\n","    g = LeakyReLU(alpha=0.2)(g)\n","    return g\n","\n","# define a decoder block\n","def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n","    # weight initialization\n","    init = RandomNormal(stddev=0.02)\n","    # add upsampling layer\n","    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n","    # add batch normalization\n","    g = BatchNormalization()(g, training=True)\n","    # conditionally add dropout\n","    if dropout:\n","        g = Dropout(0.5)(g, training=True)\n","    # merge with skip connection\n","    g = Concatenate()([g, skip_in])\n","    # relu activation\n","    g = Activation('relu')(g)\n","    return g\n","\n","# define the standalone generator model\n","def define_generator(image_shape):\n","    # weight initialization\n","    init = RandomNormal(stddev=0.02)\n","    # image input\n","    in_image = Input(shape=image_shape)\n","    # encoder model\n","    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n","    e2 = define_encoder_block(e1, 128)\n","    e3 = define_encoder_block(e2, 256)\n","    e4 = define_encoder_block(e3, 512)\n","    e5 = define_encoder_block(e4, 512)\n","    #e6 = define_encoder_block(e5, 512)\n","    #e7 = define_encoder_block(e6, 512)\n","    # bottleneck, no batch norm and relu\n","    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e5)\n","    b = Activation('relu')(b)\n","    # decoder model\n","    #d1 = decoder_block(b, e7, 512)\n","    #d2 = decoder_block(d1, e6, 512)\n","    d3 = decoder_block(b, e5, 512)\n","    d4 = decoder_block(d3, e4, 512, dropout=False)\n","    d5 = decoder_block(d4, e3, 256, dropout=False)\n","    d6 = decoder_block(d5, e2, 128, dropout=False)\n","    d7 = decoder_block(d6, e1, 64, dropout=False)\n","    # output\n","    g = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n","    out_image = Activation('tanh')(g)\n","    # define model\n","    model = Model(in_image, out_image)\n","    return model"],"id":"similar-rolling","execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"brutal-branch","executionInfo":{"status":"ok","timestamp":1615814372050,"user_tz":-330,"elapsed":1129,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model, image_shape):\n","    # make weights in the discriminator not trainable\n","    for layer in d_model.layers:\n","        if not isinstance(layer, BatchNormalization):\n","            layer.trainable = False\n","    # define the source image\n","    in_src = Input(shape=image_shape)\n","    # connect the source image to the generator input\n","    gen_out = g_model(in_src)\n","    # connect the source input and generator output to the discriminator input\n","    dis_out = d_model([in_src, gen_out])\n","    # src image as input, generated image and classification output\n","    model = Model(in_src, [dis_out, gen_out])\n","    # compile model\n","    opt = Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n","    return model"],"id":"brutal-branch","execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"accomplished-florist","executionInfo":{"status":"ok","timestamp":1615814374646,"user_tz":-330,"elapsed":1037,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["# select a batch of random samples, returns images and target\n","def generate_real_samples(dataset, n_samples, patch_shape):\n","    # unpack dataset\n","    trainA, trainB = dataset\n","    # choose random instances\n","    ix = randint(0, trainA.shape[0], n_samples)\n","    # retrieve selected images\n","    X1, X2 = trainA[ix], trainB[ix]\n","    # generate 'real' class labels (1)\n","    y = ones((n_samples, patch_shape, 4, 1))     # changed patch_shape argument to 4 \n","    return [X1, X2], y\n","\n","# generate a batch of images, returns images and targets\n","def generate_fake_samples(g_model, samples, patch_shape):\n","    # generate fake instance\n","    X = g_model.predict(samples)\n","    # create 'fake' class labels (0)\n","    y = zeros((len(X), patch_shape, 4, 1))    # changed patch_shape argument to 4\n","    return X, y"],"id":"accomplished-florist","execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"brazilian-valentine","executionInfo":{"status":"ok","timestamp":1615814378544,"user_tz":-330,"elapsed":1061,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["# generate samples and save as a plot and save the model\n","def summarize_performance(step, g_model, dataset, n_samples=3):\n","    # select a sample of input images\n","    [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n","    # generate a batch of fake samples\n","    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n","    # scale all pixels from [-1,1] to [0,1]\n","    X_realA = (X_realA + 1) / 2.0\n","    X_realB = (X_realB + 1) / 2.0\n","    X_fakeB = (X_fakeB + 1) / 2.0\n","    # plot real source images\n","    for i in range(n_samples):\n","        pyplot.subplot(3, n_samples, 1 + i)\n","        pyplot.axis('off')\n","        pyplot.imshow(X_realA[i])\n","    # plot generated target image\n","    for i in range(n_samples):\n","        pyplot.subplot(3, n_samples, 1 + n_samples + i)\n","        pyplot.axis('off')\n","        pyplot.imshow(X_fakeB[i])\n","    # plot real target image\n","    for i in range(n_samples):\n","        pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n","        pyplot.axis('off')\n","        pyplot.imshow(X_realB[i])\n","    # save plot to file\n","    filename1 = 'plot_%06d.png' % (step+1)\n","    pyplot.savefig(filename1)\n","    pyplot.close()\n","    # save the generator model\n","    filename2 = 'model_%06d.h5' % (step+1)\n","    g_model.save(filename2)\n","    print('>Saved: %s and %s' % (filename1, filename2))"],"id":"brazilian-valentine","execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"heard-dancing","executionInfo":{"status":"ok","timestamp":1615814381745,"user_tz":-330,"elapsed":1235,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["# train pix2pix models\n","def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n","    # determine the output square shape of the discriminator\n","    n_patch = d_model.output_shape[1]\n","    # unpack dataset\n","    trainA, trainB = dataset\n","    # calculate the number of batches per training epoch\n","    bat_per_epo = int(len(trainA) / n_batch)\n","    # calculate the number of training iterations\n","    n_steps = bat_per_epo * n_epochs\n","    # manually enumerate epochs\n","    for i in range(n_steps):\n","        # select a batch of real samples\n","        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n","        # generate a batch of fake samples\n","        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n","        # update discriminator for real samples\n","        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n","        # update discriminator for generated samples\n","        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n","        # update the generator\n","        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n","        # summarize performance\n","        print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n","        # summarize model performance\n","        if (i+1) % (bat_per_epo * 10) == 0:\n","            summarize_performance(i, g_model, dataset)"],"id":"heard-dancing","execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"choice-argument","executionInfo":{"status":"ok","timestamp":1615814385481,"user_tz":-330,"elapsed":3042,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["# load image data\n","dataset = [inputArrays, targetArrays]\n","\n","# define input shape based on the loaded dataset\n","image_shape = dataset[0].shape[1:]\n","\n","# define the models\n","d_model = define_discriminator(image_shape)\n","g_model = define_generator(image_shape)\n","\n","# define the composite model\n","gan_model = define_gan(g_model, d_model, image_shape)"],"id":"choice-argument","execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"residential-selection","executionInfo":{"status":"error","timestamp":1615817689184,"user_tz":-330,"elapsed":16658,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}},"outputId":"6f7ba9ba-f3e1-43de-860a-2e02dd14b1c8"},"source":["# display arrays/images in dataset\n","\n","# load the dataset\n","src_images, tar_images = generate_fake_samples(g_model,inputArrays,4)\n","print('Loaded: ', src_images.shape, tar_images.shape)\n","\n","# plot source images\n","n_samples = 3\n","\n","pyplot.figure(figsize=(50, 20))\n","\n","for i in range(n_samples):\n","    pyplot.subplot(2, n_samples, 10 + i)\n","    pyplot.axis('off')\n","    pyplot.imshow(src_images[i].astype('uint8'))\n","    \n","# plot target image\n","for i in range(n_samples):\n","    pyplot.subplot(2, n_samples,5 + n_samples + i)\n","    pyplot.axis('off')\n","    pyplot.imshow(tar_images[i].astype('uint8'))\n","    \n","pyplot.show()"],"id":"residential-selection","execution_count":34,"outputs":[{"output_type":"stream","text":["Loaded:  (14855, 128, 64, 1) (14855, 4, 4, 1)\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-b30a3239e35e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1417\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_axes_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     raise ValueError(\n\u001b[0;32m---> 66\u001b[0;31m                         f\"num must be 1 <= num <= {rows*cols}, not {num}\")\n\u001b[0m\u001b[1;32m     67\u001b[0m                 self._subplotspec = GridSpec(\n\u001b[1;32m     68\u001b[0m                         rows, cols, figure=self.figure)[int(num) - 1]\n","\u001b[0;31mValueError\u001b[0m: num must be 1 <= num <= 6, not 10"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 3600x1440 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"sweet-playing","executionInfo":{"status":"ok","timestamp":1615808690519,"user_tz":-330,"elapsed":2095,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":[""],"id":"sweet-playing","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"surface-stroke","executionInfo":{"status":"ok","timestamp":1615808693905,"user_tz":-330,"elapsed":1844,"user":{"displayName":"Monika Gautam","photoUrl":"","userId":"03290835531453483941"}}},"source":["# train model\n","#train(d_model, g_model, gan_model, dataset)"],"id":"surface-stroke","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"OyxcpEvws_yl"},"source":[""],"id":"OyxcpEvws_yl","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C0tA9hxitZoZ"},"source":[""],"id":"C0tA9hxitZoZ","execution_count":null,"outputs":[]}]}